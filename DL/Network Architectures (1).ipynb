{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshita/.local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:219: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.Scale(28,28),\n",
    "                                transforms.ToTensor(), \n",
    "                               transforms.Normalize([0.5],[0.5]),\n",
    "                             ])\n",
    "                              \n",
    "trainset = datasets.MNIST('MNIST_data/', download = True, train = True,transform= transform) \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,shuffle=True)                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3199, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10))\n",
    "#Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "#Flatten Images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "#Forward pass get our logits\n",
    "logits = model(images)\n",
    "#Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits,labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2996, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model =  nn.Sequential(nn.Linear(784,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10),\n",
    "                     nn.LogSoftmax(dim=1))\n",
    "\n",
    "#Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "#Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "#Flatten Images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "#Forward pass get our logits\n",
    "logits = model(images)\n",
    "#Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits,labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6236,  0.4423],\n",
      "        [ 0.0521,  0.0625]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(2,2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3888, 0.1957],\n",
      "        [0.0027, 0.0039]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y=x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x7f5684104f60>\n"
     ]
    }
   ],
   "source": [
    " print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1478, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z=y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3118,  0.2212],\n",
      "        [ 0.0260,  0.0312]])\n",
      "tensor([[-0.3118,  0.2212],\n",
      "        [ 0.0260,  0.0312]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and Autograd together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10),\n",
    "                     nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logps = model(images)\n",
    "loss = criterion(logps, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before backward pass: \n",
      " None\n",
      "after backward pass: \n",
      " tensor([[-0.0032, -0.0032, -0.0032,  ..., -0.0032, -0.0032, -0.0032],\n",
      "        [ 0.0034,  0.0034,  0.0034,  ...,  0.0034,  0.0034,  0.0034],\n",
      "        [-0.0011, -0.0011, -0.0011,  ..., -0.0011, -0.0011, -0.0011],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0048,  0.0048,  0.0048,  ...,  0.0048,  0.0048,  0.0048],\n",
      "        [ 0.0039,  0.0039,  0.0039,  ...,  0.0039,  0.0039,  0.0039]])\n"
     ]
    }
   ],
   "source": [
    "print('before backward pass: \\n',model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('after backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[ 0.0262, -0.0063,  0.0213,  ..., -0.0039, -0.0098, -0.0173],\n",
      "        [ 0.0038,  0.0133,  0.0227,  ...,  0.0307,  0.0089, -0.0173],\n",
      "        [ 0.0286,  0.0288, -0.0039,  ..., -0.0124,  0.0192,  0.0196],\n",
      "        ...,\n",
      "        [ 0.0296,  0.0145,  0.0334,  ..., -0.0150, -0.0354, -0.0192],\n",
      "        [-0.0180,  0.0256,  0.0275,  ...,  0.0237,  0.0059,  0.0077],\n",
      "        [ 0.0210, -0.0298,  0.0107,  ..., -0.0020,  0.0166, -0.0039]],\n",
      "       requires_grad=True)\n",
      "Gradient -  tensor([[ 0.0009,  0.0009,  0.0009,  ...,  0.0009,  0.0009,  0.0009],\n",
      "        [ 0.0017,  0.0017,  0.0017,  ...,  0.0017,  0.0017,  0.0017],\n",
      "        [-0.0025, -0.0025, -0.0025,  ..., -0.0025, -0.0025, -0.0025],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0010, -0.0010, -0.0010,  ..., -0.0010, -0.0010, -0.0010],\n",
      "        [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights - ',model[0].weight)\n",
    "\n",
    "images,labels= next(iter(trainloader))\n",
    "images.resize_(64,784)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "output = model.forward(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradient - ',model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights =  Parameter containing:\n",
      "tensor([[ 0.0262, -0.0063,  0.0213,  ..., -0.0039, -0.0098, -0.0173],\n",
      "        [ 0.0038,  0.0133,  0.0227,  ...,  0.0307,  0.0089, -0.0173],\n",
      "        [ 0.0286,  0.0288, -0.0039,  ..., -0.0124,  0.0193,  0.0196],\n",
      "        ...,\n",
      "        [ 0.0296,  0.0145,  0.0334,  ..., -0.0150, -0.0354, -0.0192],\n",
      "        [-0.0180,  0.0256,  0.0275,  ...,  0.0237,  0.0059,  0.0077],\n",
      "        [ 0.0210, -0.0298,  0.0107,  ..., -0.0020,  0.0166, -0.0038]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "optimizer.step()\n",
    "print('Updated weights = ',model[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training for Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.628693713752954\n",
      "Training loss: 0.2828316784092485\n",
      "Training loss: 0.21802203069681297\n",
      "Training loss: 0.1720614695329783\n",
      "Training loss: 0.14346777603451186\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10),\n",
    "                     nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr = 0.03)\n",
    "\n",
    "epochs=5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images,labels in trainloader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss+= loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")\n",
    "        \n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: helper in /home/akshita/.local/lib/python3.7/site-packages (2.4.2)\r\n",
      "Requirement already satisfied: pyyaml in /home/akshita/anaconda3/lib/python3.7/site-packages (from helper) (5.1.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --user helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-12-23 10:31:46--  https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/intro-to-pytorch/helper.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 199.232.20.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|199.232.20.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 416 Range Not Satisfiable\n",
      "\n",
      "    The file is already fully retrieved; nothing to do.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -c https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/intro-to-pytorch/helper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images,labels = next(iter(trainloader))\n",
    "img = images[0].view(1,784)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model.forward(img)\n",
    "ps = F.softmax(logits,dim=1)\n",
    "helper.view_classify(img.view(1,28,28),ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
